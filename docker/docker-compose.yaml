services:
# Postgres SQL database
  postgres:
    image: postgres:16
    container_name: incident-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

# S3 Bucket storage (open source)
  minio:
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z-cpuv1
    container_name: incident-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"   # API
      - "9001:9001"   # UI
    volumes:
      - minio_data:/data

# MLFlow service
  mlflow:
    image: ghcr.io/mlflow/mlflow
    container_name: incident-mlflow
    depends_on:
      - postgres
      - minio
    env_file:
      - .env
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_DEFAULT_REGION: eu-west-2
    ports:
      - "5000:5000"
    command: ["mlflow", "server", "--host", "0.0.0.0", "--port", "5000"]

  # Airflow initialisation
  airflow-init:
    image: apache/airflow:2.9.3
    container_name: incident-airflow-init
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    command:
      - bash
      - -lc
      - >
          pip install -q psycopg2-binary
          && airflow db migrate
          && airflow users create
          --username "${AIRFLOW_USER_NAME}"
          --password "${AIRFLOW_PASSWORD}"
          --firstname "${AIRFLOW_USER_FIRSTNAME}"
          --lastname "${AIRFLOW_USER_LASTNAME}"
          --role Admin
          --email "${AIRFLOW_USER_EMAIL}"
          || true

  # Airflow service
  airflow-webserver:
    image: apache/airflow:2.9.3
    container_name: incident-airflow-web
    depends_on:
      - postgres
      - airflow-init
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
      AIRFLOW__WEBSERVER__WORKERS: "1"
    volumes:
      - ../dags:/opt/airflow/dags
      - ../logs:/opt/airflow/logs
      - ../plugins:/opt/airflow/plugins
      - ..:/opt/airflow/project
    ports:
      - "8080:8080"
    command: >
      bash -lc "pip install -q psycopg2-binary && airflow webserver"

# Airflow scheduler
  airflow-scheduler:
    image: apache/airflow:2.9.3
    container_name: incident-airflow-scheduler
    depends_on:
      - postgres
      - airflow-init
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    volumes:
      - ../dags:/opt/airflow/dags
      - ../logs:/opt/airflow/logs
      - ../plugins:/opt/airflow/plugins
      - ..:/opt/airflow/project
    command: >
      bash -lc "pip install -q psycopg2-binary && airflow scheduler"


volumes:
  postgres_data:
  minio_data:
